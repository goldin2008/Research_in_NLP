{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 演示seq2seq lib中的beam search使用方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "\n",
    "# sys.path.append('C:\\\\Users\\\\reade\\\\Documents\\\\lecture4\\\\seq2seq')\n",
    "sys.path.append('/Users/yuleinku/Google Drive/BOOK/聊天机器人Chatbot/lecture4/seq2seq')\n",
    "from seq2seq.encoders import rnn_encoder\n",
    "from seq2seq.decoders import (basic_decoder, beam_search_decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 产生/demo 合成数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "产生10个长度不一（最短3，最长8）的sequences, 其中前十个是:\n",
      "[4, 9, 2, 8, 6, 4, 9]\n",
      "[2, 9, 5, 3, 6]\n",
      "[2, 9, 9, 3, 6, 9, 8, 6]\n",
      "[9, 4, 2, 6]\n",
      "[6, 7, 6]\n",
      "[3, 3, 3, 7, 7, 2, 7]\n",
      "[7, 2, 8, 4]\n",
      "[6, 8, 8, 5]\n",
      "[8, 7, 5, 6]\n",
      "[8, 9, 7, 5, 8, 9, 4, 6]\n"
     ]
    }
   ],
   "source": [
    "PAD = 0\n",
    "EOS = 1\n",
    "\n",
    "vocab_size = 10\n",
    "input_embedding_size = 16\n",
    "\n",
    "encoder_hidden_units = 32\n",
    "decoder_hidden_units = encoder_hidden_units\n",
    "\n",
    "import helpers as data_helpers\n",
    "batch_size = 10\n",
    "\n",
    "# 一个generator，每次产生一个minibatch的随机样本\n",
    "\n",
    "batches = data_helpers.random_sequences(length_from=3, length_to=8,\n",
    "                                   vocab_lower=2, vocab_upper=10,\n",
    "                                   batch_size=batch_size)\n",
    "\n",
    "print('产生%d个长度不一（最短3，最长8）的sequences, 其中前十个是:' % batch_size)\n",
    "for seq in next(batches)[:min(batch_size, 10)]:\n",
    "    print(seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义使用beamsearch decoder的seq2seq模型\n",
    "\n",
    "### 声明placholder和定义encoder部分，同part2A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating UnidirectionalRNNEncoder in mode=train\n",
      "INFO:tensorflow:\n",
      "UnidirectionalRNNEncoder:\n",
      "  init_scale: 0.04\n",
      "  rnn_cell:\n",
      "    cell_class: BasicLSTMCell\n",
      "    cell_params: {num_units: 32}\n",
      "    dropout_input_keep_prob: 1.0\n",
      "    dropout_output_keep_prob: 1.0\n",
      "    num_layers: 1\n",
      "    residual_combiner: add\n",
      "    residual_connections: false\n",
      "    residual_dense: false\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "mode = tf.contrib.learn.ModeKeys.TRAIN\n",
    "\n",
    "with tf.name_scope('minibatch'):\n",
    "    encoder_inputs = tf.placeholder(shape=(None, None),\n",
    "                                    dtype=tf.int32,\n",
    "                                    name='encoder_inputs')\n",
    "    encoder_inputs_length = tf.placeholder(shape=(None,),\n",
    "                                           dtype=tf.int32,\n",
    "                                           name='encoder_inputs_length')\n",
    "\n",
    "    decoder_targets = tf.placeholder(shape=(None, None),\n",
    "                                     dtype=tf.int32,\n",
    "                                     name='decoder_targets')\n",
    "    decoder_targets_length = tf.placeholder(shape=(None,),\n",
    "                                            dtype=tf.int32,\n",
    "                                            name='decoder_targets_length')\n",
    "    \n",
    "    decoder_inputs = tf.placeholder(shape=(None, None),\n",
    "                                    dtype=tf.int32,\n",
    "                                    name='decoder_inputs')\n",
    "    decoder_inputs_length = tf.placeholder(shape=(None,),\n",
    "                                            dtype=tf.int32,\n",
    "                                            name='decoder_inputs_length')\n",
    "\n",
    "    decoder_initial_state = tf.placeholder(shape=(None, None),\n",
    "                                    dtype=tf.float32,\n",
    "                                    name='decoder_initial_state')\n",
    "    \n",
    "\n",
    "# 2-a. 定义encoder\n",
    "encoder_params = rnn_encoder.UnidirectionalRNNEncoder.default_params()\n",
    "encoder_params[\"rnn_cell\"][\"cell_params\"][\"num_units\"] = encoder_hidden_units\n",
    "encoder_params[\"rnn_cell\"][\"cell_class\"] = \"BasicLSTMCell\"\n",
    "encoder_params  \n",
    "\n",
    "# 2-b. 定义encoding过程\n",
    "# 输入数据转化为embedding格式\n",
    "with tf.name_scope('embedding'):\n",
    "    input_embeddings = tf.Variable(\n",
    "        tf.random_uniform([vocab_size, input_embedding_size], -1.0, 1.0),\n",
    "        dtype=tf.float32)\n",
    "    output_embeddings = tf.Variable(\n",
    "        tf.random_uniform([vocab_size, input_embedding_size], -1.0, 1.0),\n",
    "        dtype=tf.float32)\n",
    "encoder_inputs_embedded = tf.nn.embedding_lookup(input_embeddings, encoder_inputs)\n",
    "\n",
    "# 使用UnidirectionalRNNEncoder编码\n",
    "encode_fn = rnn_encoder.UnidirectionalRNNEncoder(encoder_params, mode)\n",
    "encoder_output = encode_fn(encoder_inputs_embedded, encoder_inputs_length)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义decoding模型，使用seq2seq.decoders.beam_search_decoder.BeamSearchDecoder\n",
    "1. input embedding\n",
    "2. helper <-- decoder_input, decoder_input_length\n",
    "3. basic_decoder.BasicDecoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### config decoder的选项，任何基于RNN的decoding操作都需要设定的超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'init_scale': 0.04,\n",
       " 'max_decode_length': 100,\n",
       " 'rnn_cell': {'cell_class': 'BasicLSTMCell',\n",
       "  'cell_params': {'num_units': 32},\n",
       "  'dropout_input_keep_prob': 1.0,\n",
       "  'dropout_output_keep_prob': 1.0,\n",
       "  'num_layers': 1,\n",
       "  'residual_combiner': 'add',\n",
       "  'residual_connections': False,\n",
       "  'residual_dense': False}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_params = beam_search_decoder.BeamSearchDecoder.default_params()\n",
    "decode_params[\"rnn_cell\"][\"cell_params\"][\"num_units\"] = decoder_hidden_units\n",
    "decode_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### config beam_search的选项，即beam_search操作的超参数\n",
    "\n",
    "* beam_width\n",
    "* length_penalty_weight\n",
    "* choose_successors_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BeamSearchConfig(beam_width=10, vocab_size=10, eos_token=1, length_penalty_weight=0.6, choose_successors_fn=<function choose_top_k at 0x11f814488>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from seq2seq.inference import beam_search\n",
    "config = beam_search.BeamSearchConfig(\n",
    "    beam_width = 10,\n",
    "    vocab_size = vocab_size,\n",
    "    eos_token = EOS,\n",
    "    length_penalty_weight = 0.6,\n",
    "    choose_successors_fn = beam_search.choose_top_k)\n",
    "\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from seq2seq.contrib.seq2seq import helper as decode_helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating BasicDecoder in mode=train\n",
      "INFO:tensorflow:\n",
      "BasicDecoder:\n",
      "  init_scale: 0.04\n",
      "  max_decode_length: 100\n",
      "  rnn_cell:\n",
      "    cell_class: BasicLSTMCell\n",
      "    cell_params: {num_units: 32}\n",
      "    dropout_input_keep_prob: 1.0\n",
      "    dropout_output_keep_prob: 1.0\n",
      "    num_layers: 1\n",
      "    residual_combiner: add\n",
      "    residual_connections: false\n",
      "    residual_dense: false\n",
      "\n",
      "INFO:tensorflow:Creating BeamSearchDecoder in mode=train\n",
      "INFO:tensorflow:\n",
      "BeamSearchDecoder:\n",
      "  init_scale: 0.04\n",
      "  max_decode_length: 100\n",
      "  rnn_cell:\n",
      "    cell_class: BasicLSTMCell\n",
      "    cell_params: {num_units: 32}\n",
      "    dropout_input_keep_prob: 1.0\n",
      "    dropout_output_keep_prob: 1.0\n",
      "    num_layers: 1\n",
      "    residual_combiner: add\n",
      "    residual_connections: false\n",
      "    residual_dense: false\n",
      "\n"
     ]
    }
   ],
   "source": [
    "beam_helper = decode_helper.GreedyEmbeddingHelper(\n",
    "    embedding=output_embeddings,\n",
    "    start_tokens=[0] * config.beam_width,\n",
    "    end_token=-1)\n",
    "\n",
    "decoder_fn = basic_decoder.BasicDecoder(params=decode_params,\n",
    "                                       mode=mode,\n",
    "                                       vocab_size=vocab_size)\n",
    "\n",
    "\"\"\"\n",
    "decoder_fn = create_decoder(\n",
    "    helper=beam_helper,\n",
    "    mode=tf.contrib.learn.ModeKeys.INFER)\n",
    "\"\"\"\n",
    "decoder_fn = beam_search_decoder.BeamSearchDecoder(\n",
    "    decoder=decoder_fn,\n",
    "    config=config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_inputs_embedded = tf.nn.embedding_lookup(input_embeddings, decoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('minibatch'):\n",
    "    helper = decode_helper.TrainingHelper(\n",
    "        inputs = decoder_inputs_embedded,\n",
    "        sequence_length = decoder_inputs_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating BasicDecoder in mode=train\n",
      "INFO:tensorflow:\n",
      "BasicDecoder:\n",
      "  init_scale: 0.04\n",
      "  max_decode_length: 100\n",
      "  rnn_cell:\n",
      "    cell_class: BasicLSTMCell\n",
      "    cell_params: {num_units: 32}\n",
      "    dropout_input_keep_prob: 1.0\n",
      "    dropout_output_keep_prob: 1.0\n",
      "    num_layers: 1\n",
      "    residual_combiner: add\n",
      "    residual_connections: false\n",
      "    residual_dense: false\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decoder_fn = basic_decoder.BasicDecoder(params=decode_params,\n",
    "                                       mode=mode,\n",
    "                                       vocab_size=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_output, decoder_state = decoder_fn(encoder_output.final_state, helper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(\n",
    "        labels=tf.one_hot(decoder_targets, depth=vocab_size, dtype=tf.float32), \n",
    "        logits=tf.transpose(decoder_output.logits, perm = [1, 0, 2]))\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# 通过阅读decoder_helper的定义，\n",
    "# 输入数据是batch-major\n",
    "# 而输出数据是time-major...\n",
    "# 所以需要对输出的logits做一次transpose\n",
    "# labels: [batch_size, max_length, vocab_size]\n",
    "# logits （tranpose之前）: [max_length, batch_size, vocab_size] \n",
    "loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "    logits = tf.transpose(decoder_output.logits, perm=[1,0,2]), labels = decoder_targets))\n",
    "\"\"\"\n",
    "\n",
    "train_op = tf.train.AdamOptimizer(learning_rate = 0.001).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def next_feed():\n",
    "    batch = next(batches)\n",
    "    \n",
    "    encoder_inputs_, encoder_inputs_length_ = data_helpers.batch(batch)\n",
    "    decoder_targets_, decoder_targets_length_ = data_helpers.batch(\n",
    "        [(sequence) + [EOS] for sequence in batch]\n",
    "    )\n",
    "    decoder_inputs_, decoder_inputs_length_ = data_helpers.batch(\n",
    "        [[EOS] + (sequence) for sequence in batch]\n",
    "    )\n",
    "    \n",
    "    # 在feedDict里面，key可以是一个Tensor\n",
    "    return {\n",
    "        encoder_inputs: encoder_inputs_.T,\n",
    "        decoder_inputs: decoder_inputs_.T,\n",
    "        decoder_targets: decoder_targets_.T,\n",
    "        encoder_inputs_length: encoder_inputs_length_,\n",
    "        decoder_inputs_length: decoder_inputs_length_,\n",
    "        decoder_targets_length: decoder_targets_length_\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{<tf.Tensor 'minibatch/encoder_inputs:0' shape=(?, ?) dtype=int32>: array([[8, 6, 3, 7, 2, 2, 7],\n",
       "        [5, 3, 9, 0, 0, 0, 0],\n",
       "        [8, 8, 2, 0, 0, 0, 0],\n",
       "        [9, 8, 8, 0, 0, 0, 0],\n",
       "        [2, 5, 4, 8, 8, 3, 9],\n",
       "        [7, 6, 4, 7, 9, 8, 4],\n",
       "        [9, 9, 5, 7, 5, 4, 0],\n",
       "        [8, 9, 7, 8, 2, 5, 6],\n",
       "        [2, 3, 4, 5, 0, 0, 0],\n",
       "        [2, 9, 2, 4, 0, 0, 0]], dtype=int32),\n",
       " <tf.Tensor 'minibatch/decoder_inputs:0' shape=(?, ?) dtype=int32>: array([[1, 8, 6, 3, 7, 2, 2, 7],\n",
       "        [1, 5, 3, 9, 0, 0, 0, 0],\n",
       "        [1, 8, 8, 2, 0, 0, 0, 0],\n",
       "        [1, 9, 8, 8, 0, 0, 0, 0],\n",
       "        [1, 2, 5, 4, 8, 8, 3, 9],\n",
       "        [1, 7, 6, 4, 7, 9, 8, 4],\n",
       "        [1, 9, 9, 5, 7, 5, 4, 0],\n",
       "        [1, 8, 9, 7, 8, 2, 5, 6],\n",
       "        [1, 2, 3, 4, 5, 0, 0, 0],\n",
       "        [1, 2, 9, 2, 4, 0, 0, 0]], dtype=int32),\n",
       " <tf.Tensor 'minibatch/decoder_targets:0' shape=(?, ?) dtype=int32>: array([[8, 6, 3, 7, 2, 2, 7, 1],\n",
       "        [5, 3, 9, 1, 0, 0, 0, 0],\n",
       "        [8, 8, 2, 1, 0, 0, 0, 0],\n",
       "        [9, 8, 8, 1, 0, 0, 0, 0],\n",
       "        [2, 5, 4, 8, 8, 3, 9, 1],\n",
       "        [7, 6, 4, 7, 9, 8, 4, 1],\n",
       "        [9, 9, 5, 7, 5, 4, 1, 0],\n",
       "        [8, 9, 7, 8, 2, 5, 6, 1],\n",
       "        [2, 3, 4, 5, 1, 0, 0, 0],\n",
       "        [2, 9, 2, 4, 1, 0, 0, 0]], dtype=int32),\n",
       " <tf.Tensor 'minibatch/encoder_inputs_length:0' shape=(?,) dtype=int32>: [7,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  7,\n",
       "  7,\n",
       "  6,\n",
       "  7,\n",
       "  4,\n",
       "  4],\n",
       " <tf.Tensor 'minibatch/decoder_inputs_length:0' shape=(?,) dtype=int32>: [8,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  8,\n",
       "  8,\n",
       "  7,\n",
       "  8,\n",
       "  5,\n",
       "  5],\n",
       " <tf.Tensor 'minibatch/decoder_targets_length:0' shape=(?,) dtype=int32>: [8,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  8,\n",
       "  8,\n",
       "  7,\n",
       "  8,\n",
       "  5,\n",
       "  5]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd= next_feed()\n",
    "fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 7)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd[encoder_inputs].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd[decoder_inputs].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd[decoder_targets].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 我们已经定义了一个计算图\n",
    "* 图的输入端是encoder_inputs 和 encoder_inputs_length\n",
    "* 图的输出端是encoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[encoder_out1, decoder_out1] = sess.run(\n",
    "    [encoder_output, decoder_output], fd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 7, 32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_out1.outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 10, 32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_out1.cell_output.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 10, 10)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_out1.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 10)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_out1.predicted_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder output information:\n",
      "(10, 7, 32)\n",
      "(10, 32)\n",
      "(10, 32)\n"
     ]
    }
   ],
   "source": [
    "print('encoder output information:')\n",
    "print(encoder_out1.outputs.shape)\n",
    "print(encoder_out1.final_state.c.shape)\n",
    "print(encoder_out1.final_state.h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder output information:\n",
      "(8, 10)\n"
     ]
    }
   ],
   "source": [
    "print('decoder output information:')\n",
    "print(decoder_out1.predicted_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 10)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_out1.predicted_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_inputs:\n",
      "[5 4 6 3 4 5 2 6]\n",
      "decoder_inputs:\n",
      "[1 5 4 6 3 4 5 2 6]\n",
      "decoder_targets:\n",
      "[5 4 6 3 4 5 2 6 1]\n"
     ]
    }
   ],
   "source": [
    "x = next_feed()\n",
    "print('encoder_inputs:')\n",
    "print(x[encoder_inputs][0,:])\n",
    "print('decoder_inputs:')\n",
    "print(x[decoder_inputs][0,:])\n",
    "print('decoder_targets:')\n",
    "print(x[decoder_targets][0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "产生100个长度不一的sequence\n",
      "其中前十个是:\n",
      "[9, 6, 2, 9]\n",
      "[3, 2, 4, 6, 6]\n",
      "[4, 5, 4, 6]\n",
      "[3, 6, 9, 2, 3, 8, 5]\n",
      "[2, 7, 6]\n",
      "[5, 2, 8]\n",
      "[3, 6, 6, 4]\n",
      "[4, 9, 8, 9, 6, 2, 8]\n",
      "[2, 6, 2, 2]\n",
      "[4, 9, 5, 7]\n"
     ]
    }
   ],
   "source": [
    "def next_feed():\n",
    "    batch = next(batches)\n",
    "    \n",
    "    encoder_inputs_, encoder_inputs_length_ = data_helpers.batch(batch)\n",
    "    decoder_targets_, _ = data_helpers.batch(\n",
    "        [(sequence) + [EOS] for sequence in batch]\n",
    "    )\n",
    "    decoder_inputs_, decoder_inputs_length_ = data_helpers.batch(\n",
    "        [[EOS] + (sequence) for sequence in batch]\n",
    "    )\n",
    "    \n",
    "    # 在feedDict里面，key可以是一个Tensor\n",
    "    return {\n",
    "        encoder_inputs: encoder_inputs_.T,\n",
    "        decoder_inputs: decoder_inputs_.T,\n",
    "        decoder_targets: decoder_targets_.T,\n",
    "        encoder_inputs_length: encoder_inputs_length_,\n",
    "        decoder_inputs_length: decoder_inputs_length_\n",
    "    }\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "batches = data_helpers.random_sequences(length_from=3, length_to=8,\n",
    "                                        vocab_lower=2, vocab_upper=10,\n",
    "                                        batch_size=batch_size)\n",
    "\n",
    "print('产生100个长度不一的sequence')\n",
    "print('其中前十个是:')\n",
    "for seq in next(batches)[:10]:\n",
    "    print(seq)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "  minibatch loss: 2.285630226135254\n",
      "  sample 1:\n",
      "    input     > [6 7 6 6 0 0 0 0]\n",
      "    predicted > [8 6 6 6 6 6 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [4 2 7 6 0 0 0 0]\n",
      "    predicted > [7 7 5 9 6 9 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [3 8 5 8 7 9 9 0]\n",
      "    predicted > [9 9 9 9 2 0 9 9 0]\n",
      "\n",
      "batch 100\n",
      "  minibatch loss: 1.3210663795471191\n",
      "  sample 1:\n",
      "    input     > [7 9 5 5 6 5 0 0]\n",
      "    predicted > [5 5 5 5 5 5 1 0 0]\n",
      "  sample 2:\n",
      "    input     > [3 2 8 4 7 5 0 0]\n",
      "    predicted > [7 7 7 5 5 1 1 0 0]\n",
      "  sample 3:\n",
      "    input     > [6 9 4 8 9 9 6 3]\n",
      "    predicted > [9 9 9 9 9 9 9 1 1]\n",
      "\n",
      "batch 200\n",
      "  minibatch loss: 0.865583062171936\n",
      "  sample 1:\n",
      "    input     > [5 8 6 2 9 6 0 0]\n",
      "    predicted > [6 6 6 6 6 6 1 0 0]\n",
      "  sample 2:\n",
      "    input     > [9 8 5 8 0 0 0 0]\n",
      "    predicted > [8 8 8 8 1 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [9 5 7 4 4 5 4 5]\n",
      "    predicted > [4 4 4 4 4 5 4 1 1]\n",
      "\n",
      "batch 300\n",
      "  minibatch loss: 0.6636637449264526\n",
      "  sample 1:\n",
      "    input     > [6 3 6 4 2 4 8 0]\n",
      "    predicted > [6 3 4 4 4 4 8 1 0]\n",
      "  sample 2:\n",
      "    input     > [5 8 8 9 0 0 0 0]\n",
      "    predicted > [8 8 8 9 1 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [6 8 3 2 7 0 0 0]\n",
      "    predicted > [6 8 3 2 7 1 0 0 0]\n",
      "\n",
      "batch 400\n",
      "  minibatch loss: 0.572221040725708\n",
      "  sample 1:\n",
      "    input     > [2 2 5 6 0 0 0 0]\n",
      "    predicted > [2 2 5 6 1 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [5 7 8 2 0 0 0 0]\n",
      "    predicted > [7 7 8 2 1 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [6 9 6 5 3 6 8 0]\n",
      "    predicted > [6 6 6 5 3 6 8 1 0]\n",
      "\n",
      "batch 500\n",
      "  minibatch loss: 0.3666137754917145\n",
      "  sample 1:\n",
      "    input     > [3 3 2 7 5 0 0 0]\n",
      "    predicted > [3 3 2 7 5 1 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [6 7 4 0 0 0 0 0]\n",
      "    predicted > [6 7 4 1 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [9 9 2 0 0 0 0 0]\n",
      "    predicted > [9 9 2 1 0 0 0 0 0]\n",
      "\n",
      "batch 600\n",
      "  minibatch loss: 0.33198168873786926\n",
      "  sample 1:\n",
      "    input     > [7 6 9 7 3 8 9 9]\n",
      "    predicted > [7 6 9 7 9 9 9 9 1]\n",
      "  sample 2:\n",
      "    input     > [3 9 4 9 9 3 2 3]\n",
      "    predicted > [9 9 9 9 3 3 2 3 1]\n",
      "  sample 3:\n",
      "    input     > [2 6 8 3 6 9 3 8]\n",
      "    predicted > [2 6 6 3 6 9 3 8 1]\n",
      "\n",
      "batch 700\n",
      "  minibatch loss: 0.23956990242004395\n",
      "  sample 1:\n",
      "    input     > [8 6 8 6 4 9 0 0]\n",
      "    predicted > [8 6 8 6 4 9 1 0 0]\n",
      "  sample 2:\n",
      "    input     > [7 7 5 6 2 0 0 0]\n",
      "    predicted > [7 7 5 6 2 1 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [2 3 2 4 0 0 0 0]\n",
      "    predicted > [2 3 2 4 1 0 0 0 0]\n",
      "\n",
      "batch 800\n",
      "  minibatch loss: 0.24618464708328247\n",
      "  sample 1:\n",
      "    input     > [4 4 2 8 0 0 0 0]\n",
      "    predicted > [4 4 2 8 1 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [9 3 7 9 9 0 0 0]\n",
      "    predicted > [9 3 9 9 9 1 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [2 8 4 3 7 4 5 0]\n",
      "    predicted > [2 4 4 3 7 4 5 1 0]\n",
      "\n",
      "batch 900\n",
      "  minibatch loss: 0.20777569711208344\n",
      "  sample 1:\n",
      "    input     > [7 9 9 0 0 0 0 0]\n",
      "    predicted > [7 9 9 1 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [5 6 3 9 3 8 0 0]\n",
      "    predicted > [5 3 3 9 3 8 1 0 0]\n",
      "  sample 3:\n",
      "    input     > [7 8 3 7 5 0 0 0]\n",
      "    predicted > [7 8 3 7 5 1 0 0 0]\n",
      "\n",
      "batch 1000\n",
      "  minibatch loss: 0.1700473427772522\n",
      "  sample 1:\n",
      "    input     > [9 9 6 3 0 0 0 0]\n",
      "    predicted > [9 9 6 3 1 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [8 8 4 5 2 5 0 0]\n",
      "    predicted > [8 8 4 5 2 5 1 0 0]\n",
      "  sample 3:\n",
      "    input     > [9 5 7 2 8 4 0 0]\n",
      "    predicted > [9 5 7 2 8 4 1 0 0]\n",
      "\n",
      "batch 1100\n",
      "  minibatch loss: 0.20213639736175537\n",
      "  sample 1:\n",
      "    input     > [6 3 5 6 8 9 8 9]\n",
      "    predicted > [6 3 6 6 8 9 8 9 1]\n",
      "  sample 2:\n",
      "    input     > [2 2 6 3 2 6 7 6]\n",
      "    predicted > [2 2 6 3 6 6 6 6 1]\n",
      "  sample 3:\n",
      "    input     > [3 3 4 2 8 6 4 0]\n",
      "    predicted > [3 3 4 2 8 6 4 1 0]\n",
      "\n",
      "batch 1200\n",
      "  minibatch loss: 0.17405496537685394\n",
      "  sample 1:\n",
      "    input     > [9 8 3 5 4 7 0 0]\n",
      "    predicted > [9 8 3 5 4 8 1 0 0]\n",
      "  sample 2:\n",
      "    input     > [4 4 9 0 0 0 0 0]\n",
      "    predicted > [4 4 9 1 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [3 3 4 6 0 0 0 0]\n",
      "    predicted > [3 3 4 6 1 0 0 0 0]\n",
      "\n",
      "batch 1300\n",
      "  minibatch loss: 0.1413022130727768\n",
      "  sample 1:\n",
      "    input     > [4 5 7 0 0 0 0 0]\n",
      "    predicted > [4 5 7 1 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [4 7 5 0 0 0 0 0]\n",
      "    predicted > [4 7 5 1 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [9 4 5 7 4 9 8 0]\n",
      "    predicted > [9 4 5 7 4 9 8 1 0]\n",
      "\n",
      "batch 1400\n",
      "  minibatch loss: 0.1370665729045868\n",
      "  sample 1:\n",
      "    input     > [2 5 6 2 2 7 0 0]\n",
      "    predicted > [2 5 2 2 2 7 1 0 0]\n",
      "  sample 2:\n",
      "    input     > [5 2 6 0 0 0 0 0]\n",
      "    predicted > [5 2 6 1 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [6 7 3 0 0 0 0 0]\n",
      "    predicted > [6 7 3 1 0 0 0 0 0]\n",
      "\n",
      "batch 1500\n",
      "  minibatch loss: 0.13464905321598053\n",
      "  sample 1:\n",
      "    input     > [8 4 8 3 6 3 9 2]\n",
      "    predicted > [8 4 8 3 6 9 9 2 1]\n",
      "  sample 2:\n",
      "    input     > [7 5 6 9 9 3 4 0]\n",
      "    predicted > [7 5 9 9 9 4 4 1 0]\n",
      "  sample 3:\n",
      "    input     > [4 7 8 0 0 0 0 0]\n",
      "    predicted > [4 7 8 1 0 0 0 0 0]\n",
      "\n",
      "batch 1600\n",
      "  minibatch loss: 0.11442732065916061\n",
      "  sample 1:\n",
      "    input     > [3 2 3 4 6 5 9 0]\n",
      "    predicted > [3 2 3 4 6 5 9 1 0]\n",
      "  sample 2:\n",
      "    input     > [2 9 3 0 0 0 0 0]\n",
      "    predicted > [2 9 3 1 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [5 7 5 5 8 0 0 0]\n",
      "    predicted > [5 5 5 5 8 1 0 0 0]\n",
      "\n",
      "batch 1700\n",
      "  minibatch loss: 0.10922344028949738\n",
      "  sample 1:\n",
      "    input     > [8 4 8 2 6 4 9 2]\n",
      "    predicted > [8 4 8 2 6 4 9 2 1]\n",
      "  sample 2:\n",
      "    input     > [7 2 4 4 4 5 0 0]\n",
      "    predicted > [7 4 4 4 4 5 1 0 0]\n",
      "  sample 3:\n",
      "    input     > [2 9 8 6 0 0 0 0]\n",
      "    predicted > [2 9 8 6 1 0 0 0 0]\n",
      "\n",
      "batch 1800\n",
      "  minibatch loss: 0.09058064967393875\n",
      "  sample 1:\n",
      "    input     > [5 3 2 5 7 7 8 0]\n",
      "    predicted > [5 3 2 5 7 7 8 1 0]\n",
      "  sample 2:\n",
      "    input     > [5 3 4 2 0 0 0 0]\n",
      "    predicted > [5 3 4 2 1 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [4 2 8 0 0 0 0 0]\n",
      "    predicted > [4 2 8 1 0 0 0 0 0]\n",
      "\n",
      "batch 1900\n",
      "  minibatch loss: 0.08028463274240494\n",
      "  sample 1:\n",
      "    input     > [9 7 4 3 9 0 0 0]\n",
      "    predicted > [9 7 4 3 9 1 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [8 8 7 5 9 0 0 0]\n",
      "    predicted > [8 8 7 5 9 1 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [8 7 3 9 4 7 9 2]\n",
      "    predicted > [8 7 3 9 4 7 9 2 1]\n",
      "\n",
      "batch 2000\n",
      "  minibatch loss: 0.08217569440603256\n",
      "  sample 1:\n",
      "    input     > [8 6 7 7 7 5 0 0]\n",
      "    predicted > [8 6 7 7 7 5 1 0 0]\n",
      "  sample 2:\n",
      "    input     > [5 5 8 6 5 6 2 7]\n",
      "    predicted > [5 5 8 6 5 6 7 7 1]\n",
      "  sample 3:\n",
      "    input     > [3 8 5 5 0 0 0 0]\n",
      "    predicted > [3 8 5 5 1 0 0 0 0]\n",
      "\n",
      "batch 2100\n",
      "  minibatch loss: 0.08191096782684326\n",
      "  sample 1:\n",
      "    input     > [8 3 9 4 9 0 0 0]\n",
      "    predicted > [8 3 9 4 9 1 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [6 3 9 0 0 0 0 0]\n",
      "    predicted > [6 3 9 1 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [6 3 8 8 6 8 4 0]\n",
      "    predicted > [6 3 8 8 6 8 4 1 0]\n",
      "\n",
      "batch 2200\n",
      "  minibatch loss: 0.07074698805809021\n",
      "  sample 1:\n",
      "    input     > [9 3 6 5 3 4 8 7]\n",
      "    predicted > [9 3 6 5 3 4 8 7 1]\n",
      "  sample 2:\n",
      "    input     > [6 7 4 7 2 4 5 0]\n",
      "    predicted > [6 7 4 7 2 5 5 1 0]\n",
      "  sample 3:\n",
      "    input     > [8 5 5 6 2 3 0 0]\n",
      "    predicted > [8 5 5 6 2 3 1 0 0]\n",
      "\n",
      "batch 2300\n",
      "  minibatch loss: 0.080879807472229\n",
      "  sample 1:\n",
      "    input     > [4 3 6 9 4 2 0 0]\n",
      "    predicted > [4 3 6 9 4 2 1 0 0]\n",
      "  sample 2:\n",
      "    input     > [9 8 3 9 6 2 9 0]\n",
      "    predicted > [9 8 3 9 6 2 9 1 0]\n",
      "  sample 3:\n",
      "    input     > [8 5 4 5 8 0 0 0]\n",
      "    predicted > [8 5 4 5 8 1 0 0 0]\n",
      "\n",
      "batch 2400\n",
      "  minibatch loss: 0.06678621470928192\n",
      "  sample 1:\n",
      "    input     > [2 2 7 8 5 7 0 0]\n",
      "    predicted > [2 2 7 8 5 7 1 0 0]\n",
      "  sample 2:\n",
      "    input     > [2 2 6 0 0 0 0 0]\n",
      "    predicted > [2 2 6 1 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [7 3 4 8 0 0 0 0]\n",
      "    predicted > [7 3 4 8 1 0 0 0 0]\n",
      "\n",
      "batch 2500\n",
      "  minibatch loss: 0.0663120374083519\n",
      "  sample 1:\n",
      "    input     > [9 4 8 7 7 0 0 0]\n",
      "    predicted > [9 4 8 7 7 1 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [2 8 6 9 8 4 2 3]\n",
      "    predicted > [2 8 6 9 8 4 2 3 1]\n",
      "  sample 3:\n",
      "    input     > [9 2 5 4 4 2 9 0]\n",
      "    predicted > [9 2 5 4 4 2 9 1 0]\n",
      "\n",
      "batch 2600\n",
      "  minibatch loss: 0.05079060047864914\n",
      "  sample 1:\n",
      "    input     > [7 5 2 0 0 0 0 0]\n",
      "    predicted > [7 5 2 1 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [6 8 6 4 3 9 8 0]\n",
      "    predicted > [6 8 6 4 3 9 8 1 0]\n",
      "  sample 3:\n",
      "    input     > [2 5 8 0 0 0 0 0]\n",
      "    predicted > [2 5 8 1 0 0 0 0 0]\n",
      "\n",
      "batch 2700\n",
      "  minibatch loss: 0.06088954955339432\n",
      "  sample 1:\n",
      "    input     > [7 6 5 2 0 0 0 0]\n",
      "    predicted > [7 6 5 2 1 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [6 7 6 2 0 0 0 0]\n",
      "    predicted > [6 7 6 2 1 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [9 8 8 5 2 8 7 8]\n",
      "    predicted > [9 8 8 5 2 8 7 8 1]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 2800\n",
      "  minibatch loss: 0.05161980167031288\n",
      "  sample 1:\n",
      "    input     > [6 8 5 5 0 0 0 0]\n",
      "    predicted > [6 8 5 5 1 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [2 9 7 6 7 8 9 0]\n",
      "    predicted > [2 9 7 6 7 8 9 1 0]\n",
      "  sample 3:\n",
      "    input     > [8 9 9 0 0 0 0 0]\n",
      "    predicted > [8 9 9 1 0 0 0 0 0]\n",
      "\n",
      "batch 2900\n",
      "  minibatch loss: 0.06510461866855621\n",
      "  sample 1:\n",
      "    input     > [6 3 2 2 0 0 0 0]\n",
      "    predicted > [6 3 2 2 1 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [8 4 4 0 0 0 0 0]\n",
      "    predicted > [8 4 4 1 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [6 8 2 0 0 0 0 0]\n",
      "    predicted > [6 8 2 1 0 0 0 0 0]\n",
      "\n",
      "batch 3000\n",
      "  minibatch loss: 0.04390644654631615\n",
      "  sample 1:\n",
      "    input     > [8 4 9 4 0 0 0 0]\n",
      "    predicted > [8 4 9 4 1 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [4 5 5 6 5 5 0 0]\n",
      "    predicted > [4 5 5 6 5 5 1 0 0]\n",
      "  sample 3:\n",
      "    input     > [8 4 7 5 3 9 0 0]\n",
      "    predicted > [8 4 7 5 3 9 1 0 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss_track = []\n",
    "\n",
    "max_batches = 3001\n",
    "batches_in_epoch = 100\n",
    "\n",
    "try:\n",
    "    # 一个epoch的learning\n",
    "    for batch in range(max_batches):\n",
    "        fd = next_feed()\n",
    "        _, l = sess.run([train_op, loss], fd)\n",
    "        loss_track.append(l)\n",
    "        \n",
    "        if batch == 0 or batch % batches_in_epoch == 0:\n",
    "            print('batch {}'.format(batch))\n",
    "            print('  minibatch loss: {}'.format(sess.run(loss, fd)))\n",
    "            predict_ = sess.run(decoder_output.predicted_ids, fd)\n",
    "            for i, (inp, pred) in enumerate(zip(fd[encoder_inputs], predict_.T)):\n",
    "                print('  sample {}:'.format(i + 1))\n",
    "                print('    input     > {}'.format(inp))\n",
    "                print('    predicted > {}'.format(pred))\n",
    "                if i >= 2:\n",
    "                    break\n",
    "            print()\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    print('training interrupted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.0484 after 300100 examples (batch_size=100)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XecFeW9x/HPbyvbKMsuRYpLs2CHFREbXiyIRmOu5mpi\n1JiE2HI1uUku0RsVbzSWq4lRXyIxxhKjJrFHsBOxURaksyAgZakLyy7L9vLcP87hbGcLZ3fOmf2+\nX699MTNnzpnf48iXszPPPI855xAREX+J8boAEREJP4W7iIgPKdxFRHxI4S4i4kMKdxERH1K4i4j4\nkMJdRMSHFO4iIj6kcBcR8aE4rw6ckZHhsrKyvDq8iEhUWrRo0W7nXGZr+3kW7llZWeTk5Hh1eBGR\nqGRmm9qyny7LiIj4kMJdRMSHFO4iIj6kcBcR8SGFu4iIDyncRUR8SOEuIuJDURfuuTv2cf87uRSV\nVXldiohIxIq6cN+8p5Qn/rWejbtLvC5FRCRiRV24H943BYDNBaUeVyIiErmiLtyHpCcBCncRkYOJ\nunBPTogjIzWBLQp3EZEWRV24Awzuk8yWvQp3EZGWRGW4D01P1mUZEZGDiMpwH9wniW2F5dTWOq9L\nERGJSFEZ7plpidTUOgrV111EpFlRGe59UxMB2L2/wuNKREQiU1SGe0ZKAqBwFxFpSVSGe3pqINwL\nSio9rkREJDJFZ7inKNxFRA4mKsO9T3Ig3Bdv2utxJSIikSkqwz0+NlD260u2eVyJiEhkivO6gI5K\nTYwjKyPZ6zJERCJSVH5zB+iTEk/u9mKvyxARiUhR+819S0GZ1yWIiESsqP3mPumofl6XICISsaI2\n3E8Y0huA6ppajysREYk8URvuOcFukC8t3OJxJSIikSdqw/2rnYGbqcvyCj2uREQk8kRtuFcHh/uN\njYnaJoiIdJpWk9HMhpjZHDNbZWYrzeyWZvYxM/uDma0zs2VmNqZzyq1zwbEDAOjfM7GzDyUiEnXa\n8rW3Gvgv59xoYDxwk5mNbrTPBcCo4M9U4ImwVtmMn55zBAC9kuI7+1AiIlGn1XB3zm13zi0OLhcD\nq4FBjXa7BHjOBcwDepvZwLBXW09SQiwA5VXqLSMi0li7LlibWRZwEjC/0UuDgPrdVvJo+g9AWCUE\nx5epqK7pzMOIiESlNoe7maUCrwC3Ouf2deRgZjbVzHLMLCc/P78jHxESE2MkxMbom7uISDPaFO5m\nFk8g2F9wzr3azC5bgSH11gcHtzXgnJvpnMt2zmVnZmZ2pN4GEuNiKNI8qiIiTbSlt4wBfwJWO+ce\nbmG3N4Grg71mxgNFzrntYayzWcUV1by4YDO79pV39qFERKJKWwYOOw34HrDczJYEt90GDAVwzs0A\nZgFTgHVAKfD98Jfasi17y+jXs0dXHlJEJKK1Gu7OuU8Ba2UfB9wUrqLaz3l3aBGRCOSLxztrle0i\nIg34I9yV7iIiDfgj3JXtIiIN+CLcna65i4g04ItwLyxVX3cRkfp8Ee43vrDY6xJERCJKVIf7DRNH\neF2CiEhEiupwH9hLDy6JiDQnqsP9rCPqxqdRd0gRkTpRHe6DeieFlitrNDqkiMgBUR3usTF1oyJU\naOhfEZGQqA53MyMjNQGA219f7nE1IiKRI6rDHeCXk48C4J/LOn2EYRGRqBH14V5YWul1CSIiESfq\nw33VtroZ/0oqqj2sREQkckR9uCclxIaWSys1WbaICPgg3G+cODK0XOvU111EBHwQ7ukpCaHlymp1\nhxQRAR+Ee/2+7js1UbaICOCDcI+xunD/n9dXeFiJiEjkiPpwr//NfU+JukWKiIAPwr1etnPMYT29\nK0REJIJEfbhbvcsyxw/q5WElIiKRI+rDvb79FernLiICPgv3pz/72usSREQigi/CfcO9U7wuQUQk\novgi3GNijItPOAyAP87d4HE1IiLe80W4A+wNjg55z6zVHlciIuI934T7J1/t9roEEZGI4ZtwT4zz\nTVNERA6ZbxIxud7Qv/nFFR5WIiLiPd+E+/RLjg0t79ekHSLSzfkm3Hv2iAstv79qh4eViIh4zzfh\nnpJYF+73zsr1sBIREe/5JtyzD+/DD08f5nUZIiIRodVwN7OnzWyXmTU7WLqZTTSzIjNbEvy5I/xl\nts7MuGZClheHFhGJOG355v4MMLmVfT5xzp0Y/Ln70MvqmPpT7pXopqqIdGOthrtzbi5Q0AW1HLL6\n192PufNdDysREfFWuK65TzCzZWY228yOCdNniohIB8W1vkurFgNDnXP7zWwK8DowqrkdzWwqMBVg\n6NChYTi0iIg055C/uTvn9jnn9geXZwHxZpbRwr4znXPZzrnszMzMQz20iIi04JDD3cwGWHCuOzMb\nF/zMPYf6uSIi0nGtXpYxsxeBiUCGmeUBdwLxAM65GcBlwA1mVg2UAVc451ynVdwOe/ZX0Dc10esy\nRES6nHmVw9nZ2S4nJyfsn3vnGyt49otNAPROjmfJHeeF/RgiIl4xs0XOuezW9vPNE6oHXHzioNBy\nYWmVh5WIiHjHd+E+oFcPr0sQEfGc78J9UO8kr0sQEfGc78JdREQU7iIivqRwFxHxIV+G+3PXjQst\nV9fUeliJiIg3fBnuZx5RN7TByNtne1iJiIg3fBnuIiLdXbcI94rqGq9LEBHpUr4N9+EZKaHl4nLN\nyiQi3Ytvwz2tR92YaEVlGoZARLoX34Z7cBRiACY99LGHlYiIdD3fhvv0izXbn4h0X74N9xOG9Oal\nqeO9LkNExBO+DffG9lfopqqIdB++DveUhLqbqhEyOZSISJfwdbgfc1jP0PJn6zStq4h0H74O95iY\nuh4z1/9lkYeViIh0LV+HO0B6SkJoedGmAg8rERHpOr4P9/jYum/vK7ft87ASEZGu4/twj4upa+KM\nf633sBIRka7j+3BPSYwNLW8rKmftzmIPqxER6Rq+D/cHLjuhwfp5v5vrUSUiIl3H9+GemZbodQki\nIl3O/+Gemthg+F8Rke7A9+GeEBfDRz+f6HUZIiJdyvfh3hwNRSAiftctw/2KmfO4840VXpchItJp\nuk24P3rlSaHl+V8X8OwXmzysRkSkc3WbcJ94ZKbXJYiIdJluE+4iIt1Jtwn3xLjY1ncSEfGJbhPu\nCXExXHPq4Q22/WNRHuVVNR5VJCLSebpNuANUVNc2WP/535fywDtrPKpGRKTztBruZva0me0ys2b7\nDlrAH8xsnZktM7Mx4S8zPIakJzfZtrO43INKREQ6V1u+uT8DTD7I6xcAo4I/U4EnDr2sznH9WSOa\nbtTzTCLiQ62Gu3NuLnCwKYwuAZ5zAfOA3mY2MFwFhlNsvWn3DnBKdxHxoXBccx8EbKm3nhfcFpGe\nvja7wXptbQs7iohEsS69oWpmU80sx8xy8vPzu/LQIRmpDYcAfmflDjbuLvGkFhGRzhKOcN8KDKm3\nPji4rQnn3EznXLZzLjsz05snRo8e2LPJtgffU48ZEfGXcIT7m8DVwV4z44Ei59z2MHxup4iPbdrk\nt5dt10iRIuIrca3tYGYvAhOBDDPLA+4E4gGcczOAWcAUYB1QCny/s4rtTMUV1fTsEe91GSIiYdFq\nuDvnrmzldQfcFLaKusCK6edz7J3vNthWXaNv7iLiH93qCdUDUhPjeOK7DZ+1qla3GRHxkW4Z7gAX\nHNewK/64ez5kxdYij6oREQmvbhvuAM9dN67B+h2anUlEfKJbh/tJQ3s3WM/dUexRJSIi4dWtwz0h\nrmHzSys1/K+I+EP3Dvdm+ryLiPhBt043s6YDif1x7ga2FJR6UI2ISPh063AHmDCib4P1e2at5owH\n5nhUjYhIeHT7cP/rj8Y3u/3VxXldXImISPh0+3Bvyc/+ttTrEkREOkzhDk2eVj2gqkZPrYpIdFK4\nE3hadUh6UpPt6hopItFK4R502ZghTbbla/JsEYlSCveg/5w0ssm2a55e6EElIiKHTuEe1Fyf962F\nZZTp0oyIRCGFez0b77uQx7/T8Obq2N+8D8DekkrKqxT0IhIdWp2so7s5sdFgYqWVNWRNexuA4wf3\n4s2bT/eiLBGRdtE390ZSEmJbfG1ZnsZ7F5HooHBvpHdygtcliIgcMoW7iIgPKdxFRHxI4d6Mb554\nmNcliIgcEoV7M35/xUmsnH4+fVN0/V1EopPCvQUpiXFcOW5ok+2zlm/3oBoRkfZRuB/Ez849ghlX\nNXyo6cYXFgOwLK+QD1bt9KIsEZFWKdwPIibGmHzsQM46IrPB9qKyKi5+7DN++FyOR5WJiBycwr0N\nfn3R0Q3WT5j+nkeViIi0jcK9DUb2S+O2KUd5XYaISJsp3Nto6pkj6Nmj6VA8763cQd7eUgCypr3N\nD5/VMMEi4j2FezvMvDq7ybapzy/i9PvnhIYG/mD1rq4uS0SkCYV7O4wf3rfF187//dwurERE5OAU\n7u304zOHN7t9c0FpaPm3s1fz29mru6okEZEmFO7t9KspR/OtkwYddJ8nP97Akx9v6KKKRESaUrh3\nwPUTR3hdgojIQSncO+CI/mks/vW5DM9M8boUEZFmtSnczWyyma0xs3VmNq2Z1yeaWZGZLQn+3BH+\nUiNLekoCr1w/wesyRESa1Wq4m1ks8DhwATAauNLMRjez6yfOuRODP3eHuc6I1CclgfX3Tmnx9T9/\n9nUXViMiUqct39zHAeuccxucc5XAS8AlnVtW9IiNsRZfm/7WKmZ8vD40wbaISFdpS7gPArbUW88L\nbmtsgpktM7PZZnZMWKqLEu/eemaLr903OxeA6praripHRCRsN1QXA0Odc8cDjwKvN7eTmU01sxwz\ny8nPzw/Tob135IC0VvdZmlfEul3FXDlzHqWV1V1QlYh0Z20J963AkHrrg4PbQpxz+5xz+4PLs4B4\nM8to/EHOuZnOuWznXHZmZmbjl6PaX390ChC40dqcf3/ic855eC5fbNjDp1/t7srSRKQbaku4LwRG\nmdkwM0sArgDerL+DmQ0wMwsujwt+7p5wFxvJMlITgZbDvb5Fm/dy+2vLGXfPB51dloh0U02HOWzE\nOVdtZjcD7wKxwNPOuZVmdn3w9RnAZcANZlYNlAFXOOdcJ9Yd0Qb26sH2ovIWX9fTqyLS2VoNdwhd\napnVaNuMesuPAY+Ft7ToMqRPMr2S4pk2+ShOH5VBfnEFZzwwp83vLyqrYuW2IiaMaHI1S0Sk3doU\n7tK6pIRYlt55Xmh9SHpym97nnMPMuPGFRXy2bg9L7zyPXknxnVWmiHQTCvdOtPyu83jgnTU8P29T\ni/sM+1WDX4iYvXw7015dzmG9ejB+RF8e/vaJnV2miPiQxpbpRGk94rnr4vZ1+X/ty0BHpG1F5by6\neCtZ096mtrbb3r4QkQ5SuHey2Bjj3kuP451bz2jT/s3dhq7UA1Ai0k4K9y7wnVOGctSAnozql8rU\nFib7OGDBxoIm2+6bnUs37nwkIh1gXoVGdna2y8nJ8eTYXisqreKEu99r13suGzuYBy87nuDjBCLS\nTZnZIudc0wmdG9E3dw/0So7nuEG92vWefyzKC12PP8A5x5Mfr2drYVk4yxMRH1C4e+SNm07j+rPq\nZnT6nwuPbvU9P/vbUiqqa1iypZBFmwrYVlTOb2fn8oNnFnZmqSIShdQV0iMxMca0C47il+cfiRmY\nGb95u/VJtY/8n3dCy3/78akA7Cmp7LQ6RSQ66Zu7x2JirMPX0b/95BcAVNXUUliqgBeROgr3CJL7\nv5M79L7C0ipOvPt93l25gy0FpWwpKA29Vl5VQ3lVTbhKFJEoocsyEaRHfCxv3Xw6Nc7xkxcXs6Wg\njAkj+jIsI4UX5m9u9f0/fn5RaHnGVWO44YXFOAeJcTGs+c0FrNhaxP3v5PLUNdkkxsV2ZlNExGPq\nChmhamodn6/fzRmjMtlfUc2xd757SJ+36u7zOeXeDykuD0wUsuHeKcTEGCu3FTGwV1KbhioWEe+1\ntSukvrlHqNgY44xRgQlNUhMP/TSNvqPhPw5X/Wk+haVVrNq+j8N69eDzX02ittYxZ80uJh7Z76Bz\nw4pI5NM19yhxztH9AHjm+yeH5fM+X7+HVdv3AYFxbADO+d3H/ODZHB77aF1YjiEi3lG4R4nfX3ES\n0y8+hrOOyGTcsHQA4mKM4RkpYfn8xz76ig35JQCs3VXMW0u3sXBjAc65Fh+S+nLzXnbua3lSEhHx\njq65R6HaWkdlTS094gM3RdftKuach+eG7fOPH9yLZXlFDbadc3R/nvzeWJ76ZANvL9/Oazeexojb\nZtEnOZ4v7zivyWcs3FjAEf3TNDa9SJhp+AEfi4mxULADjOyXxvzbJhEXY4wfns7j3xlzSJ/fONgB\nPli9k4se/ZTfzs5lWV4R+4M3ZveWVjXZt7yqhstnfMGPntU/3iJe0Q1Vn+jfswfr7p0SWj9p6L8x\n4b6PQutjhvZm8ebCQzrG6uA1eoCLHvsktFxdU0tcbN33hKrgEMVL8g7teCLScQp3nzqsdxKzbzmD\nCx75hFOH9+XFqePJmvZ22D5/S0HddfiRt8/m0pMGkZwQy7srd9IrKfC/VWV1LdsKy0hJiGNfeRVV\nNbWUVtZQXes4cUjvsNUiIk3pmns3ciDcZ35vLFPrPfDkhY33XcjLCzczd+1uHv/uGEoqqklJjOPz\n9bv5zh/n87cfnxq6cSwiddp6zV3h3o28tXQbPZPiOeuIzAbbi8qq+P0Ha/nzZxu7rJY7LhrN3f9c\nBdTdwL3rG6O5661VoX1umDiCz9bt5uFvn8DIfmmh7c45nvh4Pd88cRCH9U5q8tlz1uwiv7iCb2cP\n6fyGiHQxhbt02G/+uYqnPv06tH7thCye+XyjdwUBS+84j17JgZ43G3eXMPH//gXA6zedxrRXlpG7\no5iFt5+Dc45x934Y2O++C70qV6TTKNzlkN322nL+On8zG++7kDU7innm8695ccEWzhvdn/dW7fSk\npmsnZJHWI45H2/Cg1X9PPoqh6ckcOSCVD1fvIjsrnbGH9wm9vqOonL2llQzPTGHF1iLGHp7OruJy\nXl6whavGH06fZoZkeGnBZv6+KI9XbpgQ1naJtJXCXQ6Zc47qWkd8bNMes/M37GFzQSmXZw/BOUdN\nraOksob738nlr20Y5Mwrd19yDFefmsUbS7Zyy0tLGrw29xdnc+aDc0Lr79x6BgN69qB3ciDkl+cV\n8Y3HPgVg5fTzSYqPJSY4TMOKrUWM7JfK2p3FfPLVbm46e2QXtUi6G4W7eGb3/go+Wr2L7Kw+DOqT\nxKzl2/npy0u9Livk9ilHc8+s1idGOWDl9PPZWljGeb9r+qDY4X2TGZGZyke5u0iMi6GiOtANdOmd\n57G3pJLcHcVc/5dFjOqXyp+uOZmhfZObfIZzjpcWbuGi4weS1kMPfcnBKdwlYn28Np9rnl4QWv/v\nyUdx/zu5HlbUdR66/ASGpCczLCOF6W+t5NoJWWzIL+GXrywD4PqzRnDayL6MPbwPyQkNeyrPXZvP\n/opqphw3kJpaR62r+62qqKyqU54Grqqp5YfP5nDrOaM4aWif1t/QifKLK/hy817OO2aAp3V4TeEu\nEa24vIpNe0pJTYwjKyOFTXtK2Ftaxbpd+9lXVsV1pw8L7fvvT3zOok17Q+tnHZHJleOGcP1fFjf5\n3GkXHMV9s/31D8VRA9LI3VEcWt9434V8e8YXLNhYwLxfTeLlhVv43Qdr+c4pQ7n30uMAeH7eJv65\ndBsvB6dibOyTr/LpnZTAcYPrJmrfkL+ftB7xZKYlArCvvIolmwu5+ukFDMtI4a2fnM6yvEImjMjo\ncFuqamopLq/u0BDTk38/l9wdxay+ezJJCd13PgKFu/jK6u37uOCRwFOxB3rBbMjfz7899DHDM1M4\nY2QG3zs1ixGZKTz8/lq+NWYwZwd71HQnb918Op+u2x36Tei568Zx2sgMXl2cR1ZGCo988BVPXDWG\n4+56DwjcZ5izZhdvLNkaeoL5ye+NJTUxjttfW87GPXWzep19ZCZz1uSz+Nfn0ispHucccbExbCkI\n/CPdJyUB5xyvL9nKRccfxt6SSkoqaygsreSj3F08+tE6xg1LZ8HXBaH5BNrCOUetg9F3vENFdS0L\nbptEv549KCipZFthGccO6tX6h3SiwtJK4mNjSAnD0NxtoXAX38ma9jbZh/fhH/V6qny5eS9HDkhr\ncgkDAmPczF6xnbFD0xtc675y5jziYo3/u/wEXpi/mW+dNCjUtfKVGyaw4OuCbnOZqKPSUxIoqDcx\ne2piHCumn8+bS7fxny9+SUpCLCWVLU/veMdFowG4PHswz8/bxBUnDw1dVtpXVkVKYhwJcTE457hi\n5jzmf13Q4mcNy0jhj1dnM7hPUoMxlwAKSipJ6xEXunzlnOvwnMX1VVbX8q81u0hJjOO7T80nMy2R\nhbef0+y++cUV1DpH/549Dvm4oHAXHyosraRHfGyTv8CdYePuEp76dAOLNxVy2djBpCTGcvTAnhw/\nuDfF5VX89OWlfJi7kyevGsspw/ty6eOfsWF3SafXFcl+9x8nHNKN8+SEWEqD/yCMGdqbnfsqWhxu\nuiW3njOKWyaNorKmlqc++ZoH310DwILbJjH5kU8oKKnk4hMO4xfnH0m/nokszyti9/5KNu4p4b7Z\nuZxzdD9umDiS4wb14svNezk5K50n527gouMHMiS97gvCNx79lOVbGw6w960xgygqreJP19bNuVBQ\nUsmY/30fgF9fNJozR2Uwqn8ah0LhLtLFKqprqKpx/D1nCy8v3ELujmJSE+O491vH0T8tkf+YOY/L\nxw5m/PC+lFbV8OvXV/CNEw7jlkmjuG/2aj5YvYu//fhU+qYmMOmhj71ujhD4jWR/RXVo/arxQ9lb\nWsXby7a3+J57Lz2OE4f0JjMtkZPv+aDJ6989ZSj3BO+NdITCXSTC5e7Yx/CMVBLimh95u7yqhtgY\nC11S+HLzXl5dvJUh6UkMTU/m3NEDKKuqYeveMoamJxMbY1RU1/Dywi2YGXl7S9s0pMRvvnksj89Z\nx/bgjFxxMUZ1rTe50F08e924JsOAtJXCXURwLvBw2d9ztjD9rVW8duMEisqqSIqPpaK6luysQJfL\nPfsreGH+Zm4+eyTVtY5/LMrjjFEZDO4TGLvn47X5LNxYwC/OP4rP1u3mu0/NB+BfP5/IL/6xlIUb\n9zY59rmj+3P7lKN5+P21zMndxfs/O4v1+ftJjIshPSWB4ZmpvL9qJz96rn058OF/nUVCbAwPvruG\nIelJPD5n/aH/h+pih/dN5uNfnN2h9yrcRaTLFJVV8dhHX3HpSYNJT0lgQK/23TzM3bGPZVuKOGJA\nGt98/DMgcAnkzm8cQ1yMYWbkF1ewc195g94xzjmmPr+ISUf1Y1T/NApLK3nkw6/o2SOezQWl/Pn7\nJ7Mhv4RNe0rIzkrnumcWUlBS2exvJ1OOC/Sfn7V8R5tqXnLHucTFxvDgO7k8+8WmFvcblpHC143u\nx4wfns5LU5vvptqasIa7mU0GHgFigaecc/c1et2Cr08BSoFrnXNNOyHXo3AXES9tLyojLiaGPsnx\noclmyqtqeOi9Ndx89iiSEmJJiIth7c5i9pZUsnt/oOvlD88Y1qTHzb7yKkoqqhnQsweb9pTSOzme\nksoaEuNi6J0Uzz+XbWdrYRlXnDyErYVlHD+44/MZhC3czSwWWAucC+QBC4ErnXOr6u0zBfgJgXA/\nBXjEOXfKwT5X4S4i0n7hnEN1HLDOObfBOVcJvARc0mifS4DnXMA8oLeZDWx31SIiEhZtCfdBwJZ6\n63nBbe3dBzObamY5ZpaTn5/f3lpFRKSN2hLuYeOcm+mcy3bOZWdmdqwbkIiItK4t4b4VqD9f2eDg\ntvbuIyIiXaQt4b4QGGVmw8wsAbgCeLPRPm8CV1vAeKDIOdfyI1wiItKpWh3GzDlXbWY3A+8S6Ar5\ntHNupZldH3x9BjCLQE+ZdQS6Qn6/80oWEZHWtGmMSufcLAIBXn/bjHrLDrgpvKWJiEhHdekNVRER\n6RqeDT9gZvlAy8/sHlwGsDuM5XhJbYlMfmmLX9oBassBhzvnWu1u6Fm4Hwozy2nLE1rRQG2JTH5p\ni1/aAWpLe+myjIiIDyncRUR8KFrDfabXBYSR2hKZ/NIWv7QD1JZ2icpr7iIicnDR+s1dREQOIurC\n3cwmm9kaM1tnZtO8rqc1ZrbRzJab2RIzywluSzez983sq+Cffert/6tg29aY2fneVQ5m9rSZ7TKz\nFfW2tbt2Mxsb/G+wzsz+YI1nOvCuLXeZ2dbguVkSnJcgottiZkPMbI6ZrTKzlWZ2S3B71J2Xg7Ql\nGs9LDzNbYGZLg22ZHtzu3XlxzkXND4HhD9YDw4EEYCkw2uu6Wql5I5DRaNsDwLTg8jTg/uDy6GCb\nEoFhwbbGelj7mcAYYMWh1A4sAMYDBswGLoiQttwF/LyZfSO2LcBAYExwOY3ARDqjo/G8HKQt0Xhe\nDEgNLscD84P1eHZeou2be1smDokGlwDPBpefBb5Zb/tLzrkK59zXBMbqGedBfQA45+YCBY02t6t2\nC0za0tM5N88F/s99rt57ukwLbWlJxLbFObfdBaewdM4VA6sJzJ0QdeflIG1pSSS3xTnn9gdX44M/\nDg/PS7SFe5smBYkwDvjAzBaZ2dTgtv6ubtTMHUD/4HI0tK+9tQ8KLjfeHil+YmbLgpdtDvzKHBVt\nMbMs4CQC3xKj+rw0agtE4Xkxs1gzWwLsAt53znl6XqIt3KPR6c65E4ELgJvM7Mz6Lwb/dY7KLkvR\nXHvQEwQu8Z0IbAce8ractjOzVOAV4Fbn3L76r0XbeWmmLVF5XpxzNcG/64MJfAs/ttHrXXpeoi3c\no25SEOfc1uCfu4DXCFxm2Rn89Yvgn7uCu0dD+9pb+9bgcuPtnnPO7Qz+hawF/kjdJbCIbouZxRMI\nwxecc68GN0fleWmuLdF6Xg5wzhUCc4DJeHheoi3c2zJxSMQwsxQzSzuwDJwHrCBQ8zXB3a4B3ggu\nvwlcYWaJZjYMGEXg5kokaVftwV9J95nZ+OBd/6vrvcdT1nAS90sJnBuI4LYEj/snYLVz7uF6L0Xd\neWmpLVEb7TnkAAAAxklEQVR6XjLNrHdwOQk4F8jFy/PSlXeUw/FDYFKQtQTuLt/udT2t1DqcwB3x\npcDKA/UCfYEPga+AD4D0eu+5Pdi2NXjQq6RR/S8S+LW4isC1vx90pHYgm8Bf0PXAYwQfnouAtjwP\nLAeWBf+yDYz0tgCnE/jVfhmwJPgzJRrPy0HaEo3n5Xjgy2DNK4A7gts9Oy96QlVExIei7bKMiIi0\ngcJdRMSHFO4iIj6kcBcR8SGFu4iIDyncRUR8SOEuIuJDCncRER/6f+TAD/URzp6vAAAAAElFTkSu\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x121c55278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_track)\n",
    "print('loss {:.4f} after {} examples (batch_size={})'.format(loss_track[-1], len(loss_track)*batch_size, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
