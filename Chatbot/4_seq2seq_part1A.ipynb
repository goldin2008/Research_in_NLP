{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 这一部分演示使用dynamic_rnn实现简单的seq2seq模型\n",
    "主要参考 github repo [tensorflow-seq2seq-tutorial](https://github.com/ematvey/tensorflow-seq2seq-tutorials)的第一和第二部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 产生不定长合成序列的函数\n",
    "import helpers as data_helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo-I：使用dynamic_rnn实现简单的seq2seq模型\n",
    "\n",
    "### 使用一个合成的minibatch data解释seq2seq模型\n",
    "\n",
    "### seq2seq模型任务是copy sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. 合成数据\n",
    "\n",
    "**seq2seq模型中的数据特征：不定长度的序列样本**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = [[5, 7, 8], [6, 3], [3], [1]]\n",
    "xt, xlen = data_helpers.batch(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始的4个序列样本是:\n",
      "[[5, 7, 8], [6, 3], [3], [1]]\n",
      "\n",
      "padding以后使用time-major记录的数据array: \n",
      "[[5 6 3 1]\n",
      " [7 3 0 0]\n",
      " [8 0 0 0]]\n",
      "\n",
      "padding以后使用batch-major记录的数据array: \n",
      "[[5 7 8]\n",
      " [6 3 0]\n",
      " [3 0 0]\n",
      " [1 0 0]]\n",
      "\n",
      "padding以后序列长度是: \n",
      " [3, 2, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print('原始的4个序列样本是:\\n%s' % x)\n",
    "print('\\npadding以后使用time-major记录的数据array: \\n%s' % xt)\n",
    "print('\\npadding以后使用batch-major记录的数据array: \\n%s' % xt.T)\n",
    "print('\\npadding以后序列长度是: \\n %s' % xlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`InteractiveSession`**在 理解tf的函数 和 debug一段代码 方面非常有用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PAD = 0\n",
    "EOS = 1\n",
    "\n",
    "vocab_size = 10\n",
    "input_embedding_size = 20\n",
    "\n",
    "encoder_hidden_units = 20\n",
    "decoder_hidden_units = 2 * encoder_hidden_units # bidirectional RNN, 见后面的解释"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. placeholders,模型的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('minibatch'):\n",
    "    # encoding 阶段的 placeholder\n",
    "    encoder_inputs = tf.placeholder(shape=(None, None),\n",
    "                                    dtype=tf.int32,\n",
    "                                    name='encoder_inputs')\n",
    "    encoder_inputs_length = tf.placeholder(shape=(None,),\n",
    "                                           dtype=tf.int32,\n",
    "                                           name='encoder_inputs_length')\n",
    "\n",
    "    # decoding 阶段的placeholder\n",
    "    decoder_inputs = tf.placeholder(shape=(None, None),\n",
    "                                    dtype=tf.int32,\n",
    "                                    name='decoder_inputs')\n",
    "    \n",
    "    # decoding 结束后用来计算损失函数\n",
    "    decoder_targets = tf.placeholder(shape=(None, None),\n",
    "                                     dtype=tf.int32,\n",
    "                                     name='decoder_targets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](figure/seq2seq2014.png)\n",
    "图片来自[Sutskever et al., 2014](https://arxiv.org/abs/1409.3215)\n",
    "\n",
    "**在这个图示的例子里面**\n",
    "* `encoder_inputs = ['A', 'B', 'C']`\n",
    "* `decoder_inputs = [<EOS>, 'W', 'X', 'Y', 'Z']`\n",
    "* `decoder_targets = ['W', 'X', 'Y', 'Z', <EOS>]`\n",
    "\n",
    "在图示的decoding阶段，每个时间，真实的sequence[t] 被提供给RNN-cell去预测 sequence[t+1]（近似于第二节课的RNNLM），**只适用于训练阶段**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('embedding'):\n",
    "    embeddings = tf.Variable(\n",
    "        tf.random_uniform([vocab_size, input_embedding_size], -1.0, 1.0),\n",
    "        dtype=tf.float32)\n",
    "\n",
    "encoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, encoder_inputs)\n",
    "decoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, decoder_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Encoder\n",
    "使用dynamic_rnn将一个Mini-batch样本编码，只保留每一个sequence结尾处的state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_cell = tf.nn.rnn_cell.BasicLSTMCell(encoder_hidden_units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第三节课的代码里面已经演示了dynamic_rnn进行encoding：\n",
    "```python\n",
    "_, encoder_final_state = tf.nn.dynamic_rnn(\n",
    "    cell = encoder_cell,\n",
    "    inputs = encoder_inputs_embedded,\n",
    "    sequence_length = encoder_inputs_length,\n",
    "    dtype=tf.float32,\n",
    "    time_major=True,\n",
    ")\n",
    "```\n",
    "这里我们使用双向 `dynamic_rnn`:\n",
    "\n",
    "![alt text](figure/RNN-bidirectional.png)\n",
    "图片来自于[Colah的blog](http://colah.github.io/posts/2015-09-NN-Types-FP/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    (encoder_fw_outputs, encoder_bw_outputs), \n",
    "    (encoder_fw_final_state, encoder_bw_final_state)\n",
    ") = (\n",
    "    tf.nn.bidirectional_dynamic_rnn(\n",
    "        cell_fw=encoder_cell,\n",
    "        cell_bw=encoder_cell,\n",
    "        inputs=encoder_inputs_embedded,\n",
    "        sequence_length=encoder_inputs_length,\n",
    "        dtype=tf.float32,\n",
    "        time_major=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前向和逆向lstm-RNN的final state拼接起来 （来自colah博客的图片演示了output的拼接）\n",
    "\n",
    "`final_state_c`, `final_state_h`\n",
    "\n",
    "从`[batch_size, numHidden]` 变成`[batch_size, 2*numHidden]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_final_state_c = tf.concat(\n",
    "    (encoder_fw_final_state.c, encoder_bw_final_state.c), 1)\n",
    "\n",
    "encoder_final_state_h = tf.concat(\n",
    "    (encoder_fw_final_state.h, encoder_bw_final_state.h), 1)\n",
    "\n",
    "encoder_final_state = tf.nn.rnn_cell.LSTMStateTuple(\n",
    "    c=encoder_final_state_c,\n",
    "    h=encoder_final_state_h\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "拼接前的前向和反向LSTM的状态Tensors\n",
      "\n",
      "前向:\n",
      "\tLSTMStateTuple(c=<tf.Tensor 'bidirectional_rnn/fw/fw/while/Exit_2:0' shape=(?, 20) dtype=float32>, h=<tf.Tensor 'bidirectional_rnn/fw/fw/while/Exit_3:0' shape=(?, 20) dtype=float32>)\n",
      "\n",
      "反向:\n",
      "\tLSTMStateTuple(c=<tf.Tensor 'bidirectional_rnn/bw/bw/while/Exit_2:0' shape=(?, 20) dtype=float32>, h=<tf.Tensor 'bidirectional_rnn/bw/bw/while/Exit_3:0' shape=(?, 20) dtype=float32>)\n",
      "\n",
      "拼接后的双向LSTM的状态Tensor:\n",
      "\tLSTMStateTuple(c=<tf.Tensor 'concat:0' shape=(?, 40) dtype=float32>, h=<tf.Tensor 'concat_1:0' shape=(?, 40) dtype=float32>)\n"
     ]
    }
   ],
   "source": [
    "print('拼接前的前向和反向LSTM的状态Tensors')\n",
    "print('\\n前向:')\n",
    "print('\\t%s' % repr(encoder_fw_final_state))\n",
    "print('\\n反向:')\n",
    "print('\\t%s' % repr(encoder_bw_final_state))\n",
    "print('\\n拼接后的双向LSTM的状态Tensor:')\n",
    "print('\\t%s' % repr(encoder_final_state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Vanilla 版本 Decoder\n",
    "* 使用 **`minibatch`**个输入序列在 **`encoder`** RNN的 **`final-state`** 作为 **`decoder`** 的 **`initial-state`**\n",
    "* 使用 **`dynamic_rnn`** 将一个 **`minibatch`** 的**`final_state`** 解码为**`minibatch`** 个 输出序列"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在decoding阶段，我们不知道`sequence_length`的数值，即输出sequence的长度\n",
    "\n",
    "* 如果我们提供**`decoder_inputs`**, 则**`dynamic_rnn`**返回和**`inputs`**同样长度的**outputs**\n",
    "* **`decoder_inputs`**的长度和内容是一个non-trivial的问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_cell = tf.nn.rnn_cell.BasicLSTMCell(decoder_hidden_units)\n",
    "\n",
    "decoder_outputs, decoder_final_state = tf.nn.dynamic_rnn(\n",
    "    cell = decoder_cell,\n",
    "    inputs = decoder_inputs_embedded,\n",
    "    initial_state=encoder_final_state,\n",
    "    dtype=tf.float32,\n",
    "    time_major=True,\n",
    "    scope=\"plain_decoder\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prediction and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_logits = tf.contrib.layers.linear(decoder_outputs, vocab_size)\n",
    "decoder_prediction = tf.argmax(decoder_logits, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "查看decoder_logits的维度（最后一个维度是vocab_size）：\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'fully_connected/BiasAdd:0' shape=(?, ?, 10) dtype=float32>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('查看decoder_logits的维度（最后一个维度是vocab_size）：')\n",
    "decoder_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算维度`[batch_size, maxT, vocab_size]`的`decoder_prediction` 和同样维度的解码目标`decoder_targets`之间的cross-entropy损失函数\n",
    "\n",
    "#### 这里需要注意一个问题，`<eos>`后面的`subsequence` 也会被用来计算loss\n",
    "\n",
    "以上图为例\n",
    "* 如果target是 `[W, X, Y, Z, <EOS>, <PAD>, <PAD>, <PAD>, <PAD>]`\n",
    "* decoding结果是 `[W, X, Y, Z, <EOS>, Z, Y, Z, W]`\n",
    "\n",
    "衡量这两个sequence区别的cross entropy loss 应该是多少？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stepwise_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=tf.one_hot(decoder_targets, depth=vocab_size, dtype=tf.float32),\n",
    "    logits=decoder_logits,\n",
    ")\n",
    "\n",
    "loss = tf.reduce_mean(stepwise_cross_entropy)\n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 运行forward-propagation\n",
    "\n",
    "**产生一个minibatch的sequence，实验`seq2seq model forward-propagation`，seq2seq模型的prediction任务是复制input sequence**\n",
    "\n",
    "* 在encoding阶段，我们只需要`input_sequence`\n",
    "* 在decoding阶段，我们通常需要使用两个变量\n",
    "  1. `decoder_input`： 作为RNN模型的底层输入数据，**内容见下面的例子**\n",
    "  2. `initial_state`： 作为RNN模型的初始状态，seq2seq模型里面，通常对应着encoder的final state\n",
    "* 在projection阶段：对`decoder_output`（RNN decoding模型运行的输出)通过一个linear projection预测单词ID\n",
    "* 在训练阶段，projection结束后，我们还需要一个变量来计算损失函数\n",
    "  3. `decoder_target`： 用来和decoder_output预测的单词sequence比较，计算prediction的准确性。在我们的复制任务里面，等于 `input_sequence` + `<eos>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "产生100个长度不一的sequence\n",
      "其中前十个是:\n",
      "[9, 6, 6, 5]\n",
      "[7, 5, 8, 7, 8, 5]\n",
      "[3, 4, 2, 2]\n",
      "[4, 2, 9, 8, 8]\n",
      "[8, 5, 5, 4, 6, 7, 3]\n",
      "[6, 5, 3, 8]\n",
      "[2, 2, 9]\n",
      "[8, 3, 7, 8]\n",
      "[3, 8, 2, 5, 8]\n",
      "[4, 8, 5, 3, 2, 9, 5, 9]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "\n",
    "batches = data_helpers.random_sequences(length_from=3, length_to=8,\n",
    "                                        vocab_lower=2, vocab_upper=10,\n",
    "                                        batch_size=batch_size)\n",
    "\n",
    "print('产生100个长度不一的sequence')\n",
    "print('其中前十个是:')\n",
    "for seq in next(batches)[:10]:\n",
    "    print(seq)\n",
    "\n",
    "def next_feed():\n",
    "    batch = next(batches)\n",
    "    \n",
    "    encoder_inputs_, encoder_inputs_length_ = data_helpers.batch(batch)\n",
    "    decoder_targets_, _ = data_helpers.batch(\n",
    "        [(sequence) + [EOS] for sequence in batch]\n",
    "    )\n",
    "    decoder_inputs_, _ = data_helpers.batch(\n",
    "        [[EOS] + (sequence) for sequence in batch]\n",
    "    )\n",
    "    \n",
    "    # 在feedDict里面，key可以是一个Tensor\n",
    "    return {\n",
    "        encoder_inputs: encoder_inputs_,\n",
    "        encoder_inputs_length: encoder_inputs_length_,\n",
    "        decoder_inputs: decoder_inputs_,\n",
    "        decoder_targets: decoder_targets_,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_inputs:\n",
      "[7 8 7 5 6 9 5 0]\n",
      "encoder_inputs_length:\n",
      "7\n",
      "decoder_inputs:\n",
      "[1 7 8 7 5 6 9 5 0]\n",
      "decoder_targets:\n",
      "[7 8 7 5 6 9 5 1 0]\n"
     ]
    }
   ],
   "source": [
    "x = next_feed()\n",
    "print('encoder_inputs:')\n",
    "print(x[encoder_inputs][:,0].T)\n",
    "print('encoder_inputs_length:')\n",
    "print(x[encoder_inputs_length][0])\n",
    "print('decoder_inputs:')\n",
    "print(x[decoder_inputs][:,0].T)\n",
    "print('decoder_targets:')\n",
    "print(x[decoder_targets][:,0].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred, _, l = sess.run([decoder_prediction, train_op, loss], x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder_targets\n",
      "[[7 8 7 5 6 9 5 1 0]\n",
      " [4 5 5 5 5 8 8 1 0]\n",
      " [2 5 6 6 7 2 9 6 1]\n",
      " [7 8 2 8 8 7 4 1 0]\n",
      " [7 8 7 8 8 7 3 1 0]]\n",
      "decoder_inputs\n",
      "[[1 7 8 7 5 6 9 5 0]\n",
      " [1 4 5 5 5 5 8 8 0]\n",
      " [1 2 5 6 6 7 2 9 6]\n",
      " [1 7 8 2 8 8 7 4 0]\n",
      " [1 7 8 7 8 8 7 3 0]]\n",
      "prediction\n",
      "[[7 7 3 3 3 3 3 3 7]\n",
      " [7 7 7 7 7 7 7 3 7]\n",
      " [7 1 1 1 6 6 6 3 3]\n",
      " [0 3 3 3 3 3 3 3 3]\n",
      " [4 3 3 3 3 3 3 3 3]]\n"
     ]
    }
   ],
   "source": [
    "print('decoder_targets')\n",
    "print(x[decoder_targets][:,0:5].T)\n",
    "\n",
    "print('decoder_inputs')\n",
    "print(x[decoder_inputs][:,0:5].T)\n",
    "\n",
    "print('prediction')\n",
    "print(pred[:,0:5].T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "几个训练用的样本和输出的结果，注意三者的区别\n",
    "\n",
    "```\n",
    "decoder_targets\n",
    "[[9 8 6 1 0 0 0 0 0]\n",
    " [8 3 4 7 1 0 0 0 0]\n",
    " [6 2 6 4 6 4 4 3 1]\n",
    " [3 7 6 5 5 8 1 0 0]\n",
    " [6 9 4 7 1 0 0 0 0]]\n",
    "decoder_inputs\n",
    "[[1 9 8 6 0 0 0 0 0]\n",
    " [1 8 3 4 7 0 0 0 0]\n",
    " [1 6 2 6 4 6 4 4 3]\n",
    " [1 3 7 6 5 5 8 0 0]\n",
    " [1 6 9 4 7 0 0 0 0]]\n",
    "prediction\n",
    "[[2 2 2 7 2 2 2 2 2]\n",
    " [2 2 2 1 0 2 2 2 2]\n",
    " [4 4 4 7 7 7 7 7 7]\n",
    " [2 1 1 7 2 0 0 2 2]\n",
    " [2 2 4 7 7 7 6 2 2]]\n",
    "\n",
    "```\n",
    "\n",
    "* 在这里我们将真实的input shift以后作为decoding 的 input\n",
    "\n",
    "* 在下一个实验里面，将要讨论**`decoder_input`**的其他选项\n",
    "\n",
    "![alt text](figure/seq2seq2014.png)\n",
    "再次引用此图，和上面的训练用的样本对应\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo-II：训练使用(bidirectional-)dynamic_rnn的简单的seq2seq模型\n",
    "\n",
    "相对于demo-I增加optimization部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_track = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# 将 encoding 和 decoding 数据输入计算图，得到预测的词语sequence\n",
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    pred_, loss = session.run([decoder_prediction, loss],\n",
    "        feed_dict={\n",
    "            encoder_inputs: ein_,\n",
    "            encoder_inputs_length: ein_length_,\n",
    "            decoder_inputs: din_,\n",
    "            decoder_targets: dtar_\n",
    "        })\n",
    "\n",
    "    print('decoder predictions:\\n' + str(pred_))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "  minibatch loss: 2.3100972175598145\n",
      "  sample 1:\n",
      "    input     > [6 9 2 8 7 4 0 0]\n",
      "    predicted > [7 6 8 0 3 3 3 0 7]\n",
      "  sample 2:\n",
      "    input     > [9 6 8 9 8 5 6 8]\n",
      "    predicted > [7 0 8 3 8 3 3 3 3]\n",
      "  sample 3:\n",
      "    input     > [9 8 6 8 0 0 0 0]\n",
      "    predicted > [7 0 3 3 3 3 7 7 7]\n",
      "\n",
      "batch 1000\n",
      "  minibatch loss: 0.1688162386417389\n",
      "  sample 1:\n",
      "    input     > [5 7 3 6 0 0 0 0]\n",
      "    predicted > [5 7 3 6 1 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [2 8 3 0 0 0 0 0]\n",
      "    predicted > [2 8 3 1 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [2 5 9 4 0 0 0 0]\n",
      "    predicted > [2 5 9 4 1 0 0 0 0]\n",
      "\n",
      "batch 2000\n",
      "  minibatch loss: 0.07107728719711304\n",
      "  sample 1:\n",
      "    input     > [4 3 5 3 4 0 0 0]\n",
      "    predicted > [4 3 5 3 4 1 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [9 6 8 6 7 6 0 0]\n",
      "    predicted > [9 6 8 6 7 6 1 0 0]\n",
      "  sample 3:\n",
      "    input     > [4 3 2 3 2 2 0 0]\n",
      "    predicted > [4 3 2 3 2 2 1 0 0]\n",
      "\n",
      "batch 3000\n",
      "  minibatch loss: 0.045918647199869156\n",
      "  sample 1:\n",
      "    input     > [8 7 9 2 8 5 0 0]\n",
      "    predicted > [8 7 9 2 8 5 1 0 0]\n",
      "  sample 2:\n",
      "    input     > [7 8 4 0 0 0 0 0]\n",
      "    predicted > [7 8 4 1 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [2 4 3 5 7 0 0 0]\n",
      "    predicted > [2 4 3 5 7 1 0 0 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_batches = 3001\n",
    "batches_in_epoch = 1000\n",
    "\n",
    "try:\n",
    "    # 一个epoch的learning\n",
    "    for batch in range(max_batches):\n",
    "        fd = next_feed()\n",
    "        _, _, l = sess.run([decoder_prediction, train_op, loss], fd)\n",
    "        loss_track.append(l)\n",
    "        \n",
    "        if batch == 0 or batch % batches_in_epoch == 0:\n",
    "            print('batch {}'.format(batch))\n",
    "            print('  minibatch loss: {}'.format(sess.run(loss, fd)))\n",
    "            predict_ = sess.run(decoder_prediction, fd)\n",
    "            for i, (inp, pred) in enumerate(zip(fd[encoder_inputs].T, predict_.T)):\n",
    "                print('  sample {}:'.format(i + 1))\n",
    "                print('    input     > {}'.format(inp))\n",
    "                print('    predicted > {}'.format(pred))\n",
    "                if i >= 2:\n",
    "                    break\n",
    "            print()\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    print('training interrupted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## decoder output的长度问题\n",
    "\n",
    "* 和RNNLM不同，在seq2seq模型中，decoding阶段产生的序列的长度是未知的\n",
    "* 如何设定decoding序列的长度？\n",
    "* 可以设定decoding比encoding输入序列长NUM个单位，比较decoding prediction的`<eos>`之前的subsequence和真实的decoding_target的差别作为损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.0512 after 300100 examples (batch_size=100)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x129672978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_track)\n",
    "print('loss {:.4f} after {} examples (batch_size={})'.format(loss_track[-1], len(loss_track)*batch_size, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
